\relax 
\providecommand{\transparent@use}[1]{}
\providecommand\hyper@newdestlabel[2]{}
\transparent@use{.4}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:background}{{2}{5}{Background}{chapter.2}{}}
\newlabel{ch:background@cref}{{[chapter][2][]2}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Line}{5}{section.2.1}\protected@file@percent }
\newlabel{sec:line}{{2.1}{5}{Line}{section.2.1}{}}
\newlabel{sec:line@cref}{{[section][1][2]2.1}{[1][5][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of a 2D line.\relax }}{5}{figure.caption.32}\protected@file@percent }
\newlabel{fig:generic_line}{{2.1}{5}{Example of a 2D line.\relax }{figure.caption.32}{}}
\newlabel{fig:generic_line@cref}{{[figure][1][2]2.1}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Plane}{6}{section.2.2}\protected@file@percent }
\newlabel{sec:plane}{{2.2}{6}{Plane}{section.2.2}{}}
\newlabel{sec:plane@cref}{{[section][2][2]2.2}{[1][6][]6}}
\citation{patel_hands-unsupervised_nodate}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a 3D plane.\relax }}{7}{figure.caption.37}\protected@file@percent }
\newlabel{fig:generic_plane}{{2.2}{7}{Example of a 3D plane.\relax }{figure.caption.37}{}}
\newlabel{fig:generic_plane@cref}{{[figure][2][2]2.2}{[1][7][]7}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Neural Networks}{7}{section.2.3}\protected@file@percent }
\newlabel{sec:neural-net}{{2.3}{7}{Neural Networks}{section.2.3}{}}
\newlabel{sec:neural-net@cref}{{[section][3][2]2.3}{[1][7][]7}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{paragraph*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{7}{paragraph*.40}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of a neural network. The various $a_{ij}$ represent the \textit  {j-th} neuron of \textit  {i-th} layer. Weights $w_{kj}$ represent the weight of the connection from neuron \textit  {k} of the preceding layer to neuron \textit  {j} of the current layer.\relax }}{8}{figure.caption.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{8}{paragraph*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{9}{paragraph*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{9}{paragraph*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{9}{paragraph*.48}\protected@file@percent }
\newlabel{eq:MSE}{{2.13}{9}{}{equation.2.3.13}{}}
\newlabel{eq:MSE@cref}{{[equation][13][2]2.13}{[1][9][]9}}
\@writefile{toc}{\contentsline {paragraph}{}{9}{paragraph*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Auto-Encoders}{10}{subsection.2.3.1}\protected@file@percent }
\newlabel{subsec:ae}{{2.3.1}{10}{Auto-Encoders}{subsection.2.3.1}{}}
\newlabel{subsec:ae@cref}{{[subsection][1][2,3]2.3.1}{[1][10][]10}}
\@writefile{toc}{\contentsline {paragraph}{}{10}{paragraph*.52}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Example of an architecture for an auto-encoder. The input (and output) is \textit  {2-dimensional}, thus the latent space must be \textit  {1-dimensional}.\relax }}{10}{figure.caption.53}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{10}{paragraph*.54}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{10}{paragraph*.55}\protected@file@percent }
\citation{PCA}
\citation{som_paper}
\@writefile{toc}{\contentsline {paragraph}{}{11}{paragraph*.56}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{11}{paragraph*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Self Organizing Maps}{11}{subsection.2.3.2}\protected@file@percent }
\newlabel{subsec:som}{{2.3.2}{11}{Self Organizing Maps}{subsection.2.3.2}{}}
\newlabel{subsec:som@cref}{{[subsection][2][2,3]2.3.2}{[1][11][]11}}
\@writefile{toc}{\contentsline {paragraph}{}{11}{paragraph*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{11}{paragraph*.60}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{11}{paragraph*.61}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Ideal structure of SOM. Each element of the input vector, $x_i$, is connected to each neuron of the output layer, displaced as a grid.\relax }}{12}{figure.caption.59}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{12}{paragraph*.62}\protected@file@percent }
\newlabel{eq:som_neighbor_func}{{2.16}{13}{}{equation.2.3.16}{}}
\newlabel{eq:som_neighbor_func@cref}{{[equation][16][2]2.16}{[1][13][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Image that shows the effect of the neighboring function. At time 0 several neighbors are considered, while as the time passes ever less neighbors are updated. The color represents the update's intensity; the higher the intensity, the closer the weight is to the BMU.\relax }}{13}{figure.caption.65}\protected@file@percent }
\citation{manifold}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.1}{\ignorespaces SOM Training loop\relax }}{14}{algorithm.2.1}\protected@file@percent }
\newlabel{alg:cap}{{2.1}{14}{SOM Training loop\relax }{algorithm.2.1}{}}
\newlabel{alg:cap@cref}{{[algorithm][1][2]2.1}{[1][14][]14}}
\@writefile{toc}{\contentsline {paragraph}{}{14}{paragraph*.66}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Voronoi Tessellation}{14}{section.2.4}\protected@file@percent }
\newlabel{sec:voronoi}{{2.4}{14}{Voronoi Tessellation}{section.2.4}{}}
\newlabel{sec:voronoi@cref}{{[section][4][2]2.4}{[1][14][]14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Manifold}{14}{section.2.5}\protected@file@percent }
\newlabel{sec:manifold}{{2.5}{14}{Manifold}{section.2.5}{}}
\newlabel{sec:manifold@cref}{{[section][5][2]2.5}{[1][14][]14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Classification Metrics}{15}{section.2.6}\protected@file@percent }
\newlabel{eq:tpr}{{2.21}{16}{Classification Metrics}{equation.2.6.21}{}}
\newlabel{eq:tpr@cref}{{[equation][21][2]2.21}{[1][16][]16}}
\newlabel{eq:tnr}{{2.22}{16}{Classification Metrics}{equation.2.6.22}{}}
\newlabel{eq:tnr@cref}{{[equation][22][2]2.22}{[1][16][]16}}
\@writefile{toc}{\contentsline {paragraph}{}{16}{paragraph*.73}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Receiver Operating Characteristic curve}{17}{subsection.2.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces An example of a Receiver Operating Characteristic curve, showing both the ideal curve and the curve from a generic model, with good results.\relax }}{17}{figure.caption.74}\protected@file@percent }
\@setckpt{chapters/background}{
\setcounter{page}{18}
\setcounter{equation}{22}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{2}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{6}
\setcounter{subsection}{1}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{7}
\setcounter{table}{0}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{thmt@dummyctr}{0}
\setcounter{float@type}{32}
\setcounter{parentequation}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{15}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{lstnumber}{1}
\setcounter{FancyVerbLine}{0}
\setcounter{linenumber}{1}
\setcounter{LN@truepage}{31}
\setcounter{FV@TrueTabGroupLevel}{0}
\setcounter{FV@TrueTabCounter}{0}
\setcounter{FV@HighlightLinesStart}{0}
\setcounter{FV@HighlightLinesStop}{0}
\setcounter{FancyVerbLineBreakLast}{0}
\setcounter{minted@FancyVerbLineTemp}{0}
\setcounter{minted@pygmentizecounter}{0}
\setcounter{listing}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{2}
\setcounter{bookmark@seq@number}{18}
\setcounter{NAT@ctr}{0}
\setcounter{AM@survey}{0}
\setcounter{svg@param@lastpage}{0}
\setcounter{svg@param@currpage}{-1}
\setcounter{theorem}{0}
\setcounter{proposition}{0}
\setcounter{algsubstate}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{0}
}
